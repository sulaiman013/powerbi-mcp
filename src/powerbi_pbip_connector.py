"""
Power BI PBIP (Power BI Project) Connector
Provides file-based editing for PBIP format to safely rename tables, columns, measures
without breaking report visuals.

PBIP Structure:
  project.pbip
  ProjectName.SemanticModel/
    definition.tmdl (or model.tmd)
    definition/
      tables/*.tmdl
      relationships/*.tmdl  <- Individual relationship files
      relationships.tmdl    <- Or single file
      etc.
  ProjectName.Report/
    report.json  <- Contains visual field bindings
    definition.pbir

TMDL Name Quoting Rules (Microsoft Spec):
  - Names with spaces, special chars, or reserved words MUST be quoted with single quotes
  - Examples:
    - table 'Customer Appointments'  (spaces - MUST quote)
    - table Sales                    (no spaces - no quote needed)
    - fromTable: 'My Table'          (spaces in relationship ref)
"""
import json
import logging
import os
import re
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)


# Characters that require quoting in TMDL names
TMDL_SPECIAL_CHARS = set(' \t\n\r\'\"[]{}().,;:!@#$%^&*+-=<>?/\\|`~')
TMDL_RESERVED_WORDS = {'table', 'column', 'measure', 'relationship', 'partition', 'hierarchy', 'level',
                       'annotation', 'expression', 'from', 'to', 'true', 'false', 'null'}


def needs_tmdl_quoting(name: str) -> bool:
    """
    Check if a TMDL name needs single quotes

    Rules:
    - Names with spaces need quotes
    - Names with special characters need quotes
    - Names starting with digits need quotes
    - Reserved words need quotes
    """
    if not name:
        return False

    # Check for spaces or special chars
    if any(c in TMDL_SPECIAL_CHARS for c in name):
        return True

    # Check if starts with digit
    if name[0].isdigit():
        return True

    # Check reserved words (case insensitive)
    if name.lower() in TMDL_RESERVED_WORDS:
        return True

    return False


def quote_tmdl_name(name: str) -> str:
    """
    Quote a TMDL name if needed

    Args:
        name: The name to potentially quote

    Returns:
        Quoted name if needed, otherwise original name
    """
    if needs_tmdl_quoting(name):
        # Escape any existing single quotes
        escaped = name.replace("'", "''")
        return f"'{escaped}'"
    return name


def unquote_tmdl_name(name: str) -> str:
    """Remove TMDL quotes from a name if present"""
    if name.startswith("'") and name.endswith("'"):
        # Remove outer quotes and unescape inner quotes
        return name[1:-1].replace("''", "'")
    return name


def fix_dax_table_references(dax_expression: str, table_names: List[str]) -> str:
    """
    Fix DAX expressions by quoting table names that have spaces or special chars.

    This handles cases like:
    - SUM(Leads Sales Data[Amount]) -> SUM('Leads Sales Data'[Amount])
    - CALCULATE(SUM(My Table[Col])) -> CALCULATE(SUM('My Table'[Col]))

    Args:
        dax_expression: The DAX expression to fix
        table_names: List of table names in the model (used for context)

    Returns:
        Fixed DAX expression with proper table name quoting
    """
    result = dax_expression

    for table_name in table_names:
        if needs_tmdl_quoting(table_name):
            # Find all unquoted references to this table followed by [
            # Matches: TableName[Column] but not 'TableName'[Column]
            pattern = rf"(?<!['\w]){re.escape(table_name)}(?=\s*\[)"
            replacement = quote_tmdl_name(table_name)
            result = re.sub(pattern, replacement, result)

            # Also fix function call patterns like: RELATED(TableName
            # but not: RELATED('TableName
            pattern2 = rf"(?<=[A-Za-z]\()\s*{re.escape(table_name)}(?=\s*[\[\,\)])"
            result = re.sub(pattern2, replacement, result)

    return result


@dataclass
class PBIPProject:
    """Represents a PBIP project structure"""
    root_path: Path
    pbip_file: Path
    semantic_model_folder: Optional[Path]
    report_folder: Optional[Path]
    report_json_path: Optional[Path]
    tmdl_files: List[Path]
    backup_path: Optional[Path] = None


@dataclass
class ValidationError:
    """Represents a validation error found after rename"""
    file_path: str
    line_number: int
    error_type: str
    message: str
    context: str


@dataclass
class RenameResult:
    """Result of a PBIP rename operation"""
    success: bool
    message: str
    files_modified: List[str]
    references_updated: int
    details: Optional[Dict[str, Any]] = None
    validation_errors: List[ValidationError] = field(default_factory=list)
    backup_created: Optional[str] = None


class PowerBIPBIPConnector:
    """
    PBIP Connector for file-based Power BI Project editing

    Enables safe bulk renames by editing:
    - TMDL files (semantic model definitions)
    - report.json (visual field bindings)

    Key improvements in V2.1:
    - Proper TMDL quoting for names with spaces
    - Complete relationship reference updates (fromTable/toTable)
    - Automatic backup before changes
    - Post-change validation
    """

    def __init__(self, auto_backup: bool = True):
        self.current_project: Optional[PBIPProject] = None
        self.auto_backup = auto_backup
        self._original_files: Dict[str, str] = {}  # For rollback

    @staticmethod
    def find_pbip_project_from_model_name(model_name: str, search_paths: Optional[List[str]] = None) -> Optional[PBIPProject]:
        """
        Find a PBIP project that matches the given model name

        Args:
            model_name: Name of the model (usually the database name from TOM)
            search_paths: Optional list of paths to search for PBIP projects

        Returns:
            PBIPProject if found, None otherwise
        """
        if not search_paths:
            # Default search locations
            search_paths = [
                os.path.expanduser("~/Documents"),
                os.path.expanduser("~/Desktop"),
                os.path.expanduser("~/Downloads"),
                "C:/",
            ]

        # Also check common development folders
        for base in ["C:/Users", os.path.expanduser("~")]:
            for folder in ["Projects", "Work", "Dev", "GitHub", "Repos"]:
                path = os.path.join(base, folder)
                if os.path.exists(path):
                    search_paths.append(path)

        for search_path in search_paths:
            if not os.path.exists(search_path):
                continue

            # Look for .pbip files
            try:
                for root, dirs, files in os.walk(search_path):
                    # Limit depth to avoid searching too deep
                    depth = root.replace(search_path, '').count(os.sep)
                    if depth > 5:
                        continue

                    for file in files:
                        if file.endswith('.pbip'):
                            pbip_path = Path(root) / file
                            project = PowerBIPBIPConnector._parse_pbip_project(pbip_path)
                            if project:
                                # Check if model name matches
                                if project.semantic_model_folder and model_name.lower() in project.semantic_model_folder.name.lower():
                                    logger.info(f"Found PBIP project for model '{model_name}' at: {pbip_path}")
                                    return project
            except PermissionError:
                continue

        return None

    @staticmethod
    def find_pbip_from_path(pbip_path: str) -> Optional[PBIPProject]:
        """
        Parse a PBIP project from a given path

        Args:
            pbip_path: Path to the .pbip file or project folder

        Returns:
            PBIPProject if valid, None otherwise
        """
        path = Path(pbip_path)

        # If it's a folder, look for .pbip file inside
        if path.is_dir():
            pbip_files = list(path.glob("*.pbip"))
            if pbip_files:
                path = pbip_files[0]
            else:
                return None

        if not path.exists() or not path.suffix == '.pbip':
            return None

        return PowerBIPBIPConnector._parse_pbip_project(path)

    @staticmethod
    def _parse_pbip_project(pbip_path: Path) -> Optional[PBIPProject]:
        """Parse a PBIP project structure"""
        try:
            root = pbip_path.parent

            # Find semantic model folder (.SemanticModel)
            semantic_folders = list(root.glob("*.SemanticModel"))
            semantic_model_folder = semantic_folders[0] if semantic_folders else None

            # Find report folder (.Report)
            report_folders = list(root.glob("*.Report"))
            report_folder = report_folders[0] if report_folders else None

            # Find report.json
            report_json_path = None
            if report_folder:
                report_json = report_folder / "report.json"
                if report_json.exists():
                    report_json_path = report_json

            # Find all TMDL files
            tmdl_files = []
            if semantic_model_folder:
                tmdl_files = list(semantic_model_folder.glob("**/*.tmdl"))
                tmdl_files.extend(semantic_model_folder.glob("**/*.tmd"))

            return PBIPProject(
                root_path=root,
                pbip_file=pbip_path,
                semantic_model_folder=semantic_model_folder,
                report_folder=report_folder,
                report_json_path=report_json_path,
                tmdl_files=tmdl_files
            )

        except Exception as e:
            logger.error(f"Failed to parse PBIP project: {e}")
            return None

    def load_project(self, pbip_path: str) -> bool:
        """
        Load a PBIP project for editing

        Args:
            pbip_path: Path to .pbip file or project folder

        Returns:
            True if loaded successfully
        """
        project = self.find_pbip_from_path(pbip_path)
        if project:
            self.current_project = project
            self._original_files = {}  # Clear any previous backup state
            logger.info(f"Loaded PBIP project: {project.pbip_file}")
            return True
        return False

    def get_project_info(self) -> Dict[str, Any]:
        """Get information about the loaded project"""
        if not self.current_project:
            return {"error": "No project loaded"}

        return {
            "root_path": str(self.current_project.root_path),
            "pbip_file": str(self.current_project.pbip_file),
            "semantic_model_folder": str(self.current_project.semantic_model_folder) if self.current_project.semantic_model_folder else None,
            "report_folder": str(self.current_project.report_folder) if self.current_project.report_folder else None,
            "report_json_path": str(self.current_project.report_json_path) if self.current_project.report_json_path else None,
            "tmdl_file_count": len(self.current_project.tmdl_files),
            "has_report": self.current_project.report_json_path is not None
        }

    # ==================== BACKUP & ROLLBACK ====================

    def create_backup(self) -> Optional[str]:
        """
        Create a backup of the entire PBIP project

        Returns:
            Path to backup folder, or None if failed
        """
        if not self.current_project:
            return None

        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"{self.current_project.pbip_file.stem}_backup_{timestamp}"
            backup_path = self.current_project.root_path.parent / backup_name

            # Copy entire project folder
            shutil.copytree(self.current_project.root_path, backup_path)

            self.current_project.backup_path = backup_path
            logger.info(f"Created backup at: {backup_path}")
            return str(backup_path)

        except Exception as e:
            logger.error(f"Failed to create backup: {e}")
            return None

    def _cache_file_content(self, file_path: Path) -> None:
        """Cache original file content for potential rollback"""
        if str(file_path) not in self._original_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    self._original_files[str(file_path)] = f.read()
            except Exception as e:
                logger.warning(f"Could not cache file {file_path}: {e}")

    def rollback_changes(self) -> bool:
        """
        Rollback all changes made in this session

        Returns:
            True if rollback successful
        """
        if not self._original_files:
            logger.warning("No changes to rollback")
            return False

        try:
            for file_path, content in self._original_files.items():
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)

            logger.info(f"Rolled back {len(self._original_files)} file(s)")
            self._original_files = {}
            return True

        except Exception as e:
            logger.error(f"Rollback failed: {e}")
            return False

    # ==================== VALIDATION ====================

    def validate_tmdl_syntax(self) -> List[ValidationError]:
        """
        Validate TMDL files for common syntax errors

        Returns:
            List of validation errors found
        """
        errors = []

        if not self.current_project or not self.current_project.tmdl_files:
            return errors

        # Build set of table names that need quoting
        tables_needing_quotes = set()
        try:
            for tmdl_file in self.current_project.tmdl_files:
                with open(tmdl_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                # Find all table declarations (handle both quoted and unquoted names)
                # Pattern 1: table 'Name With Spaces'
                for match in re.finditer(r"^table\s+'([^']+)'", content, re.MULTILINE):
                    table_name = match.group(1).replace("''", "'")  # Unescape quotes
                    if needs_tmdl_quoting(table_name):
                        tables_needing_quotes.add(table_name)
                # Pattern 2: table UnquotedName
                for match in re.finditer(r"^table\s+(\w+)\s*$", content, re.MULTILINE):
                    table_name = match.group(1)
                    if needs_tmdl_quoting(table_name):
                        tables_needing_quotes.add(table_name)
        except Exception:
            pass

        for tmdl_file in self.current_project.tmdl_files:
            try:
                with open(tmdl_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()

                for i, line in enumerate(lines, 1):
                    stripped = line.strip()

                    # Check for unquoted names with spaces in declarations
                    # Pattern: "table Name With Spaces" (without quotes)
                    if stripped.startswith('table '):
                        name_part = stripped[6:].strip()
                        if ' ' in name_part and not name_part.startswith("'"):
                            errors.append(ValidationError(
                                file_path=str(tmdl_file),
                                line_number=i,
                                error_type="UNQUOTED_NAME",
                                message=f"Table name with spaces must be quoted: {name_part}",
                                context=stripped
                            ))

                    # Check fromTable/toTable references
                    for prefix in ['fromTable:', 'toTable:']:
                        if prefix in stripped:
                            # Extract the name after the prefix
                            match = re.search(rf'{prefix}\s*(.+?)(?:\s*$|\s+\w+:)', stripped)
                            if match:
                                name_part = match.group(1).strip()
                                if ' ' in name_part and not name_part.startswith("'"):
                                    errors.append(ValidationError(
                                        file_path=str(tmdl_file),
                                        line_number=i,
                                        error_type="UNQUOTED_REFERENCE",
                                        message=f"Relationship reference with spaces must be quoted: {name_part}",
                                        context=stripped
                                    ))

                    # Check for unquoted table references in DAX (measure/column expressions)
                    if 'expression:' in stripped or '=' in stripped:
                        # Check for unquoted table references that need quoting
                        for table_name in tables_needing_quotes:
                            # Pattern: unquoted TableName[Column] where table has spaces
                            if re.search(rf"(?<!['\w]){re.escape(table_name)}(?=\s*\[)", stripped):
                                errors.append(ValidationError(
                                    file_path=str(tmdl_file),
                                    line_number=i,
                                    error_type="UNQUOTED_TABLE_IN_DAX",
                                    message=f"Table '{table_name}' in DAX expression must be quoted: use '{quote_tmdl_name(table_name)}' instead of '{table_name}'",
                                    context=stripped
                                ))
                                break  # Only report once per line

            except Exception as e:
                errors.append(ValidationError(
                    file_path=str(tmdl_file),
                    line_number=0,
                    error_type="FILE_ERROR",
                    message=str(e),
                    context=""
                ))

        return errors

    def fix_all_dax_quoting(self) -> Dict[str, Any]:
        """
        Fix all DAX expressions in TMDL files by properly quoting table names with spaces.

        This scans all measures and expressions and quotes table names that have spaces
        but are referenced without quotes.

        Returns:
            Dict with files_modified, references_fixed count, and validation_errors
        """
        if not self.current_project or not self.current_project.tmdl_files:
            return {"files_modified": [], "count": 0, "errors": []}

        files_modified = []
        total_fixes = 0
        errors = []

        # First, collect all table names in the project
        table_names = set()
        try:
            for tmdl_file in self.current_project.tmdl_files:
                with open(tmdl_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                # Find all table declarations - both quoted and unquoted
                # Pattern 1: table 'Name With Spaces'
                for match in re.finditer(r"^(?:\s*)table\s+'([^']+)'", content, re.MULTILINE):
                    table_name = match.group(1).replace("''", "'")  # Unescape quotes
                    table_names.add(table_name)
                # Pattern 2: table UnquotedName
                for match in re.finditer(r"^(?:\s*)table\s+(\w+)\s*$", content, re.MULTILINE):
                    table_names.add(match.group(1))
        except Exception as e:
            logger.warning(f"Could not extract table names: {e}")

        # Filter to only tables that need quoting
        tables_needing_quotes = [t for t in table_names if needs_tmdl_quoting(t)]

        if not tables_needing_quotes:
            return {"files_modified": [], "count": 0, "errors": []}

        # Now process each file and fix DAX expressions
        for tmdl_file in self.current_project.tmdl_files:
            try:
                self._cache_file_content(tmdl_file)

                with open(tmdl_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                original_content = content
                file_fixes = 0

                # Fix each table that needs quoting
                for table_name in tables_needing_quotes:
                    table_quoted = quote_tmdl_name(table_name)
                    escaped_name = re.escape(table_name)

                    # Pattern 1: TableName[Column] -> 'TableName'[Column]
                    pattern1 = rf"(?<!['\w]){escaped_name}(?=\s*\[)"
                    content_before = content
                    content = re.sub(pattern1, table_quoted, content)
                    file_fixes += len(re.findall(pattern1, content_before))

                    # Pattern 2: Handle function calls like CALCULATE(SUM(TableName[Col]))
                    # This pattern matches unquoted table names in DAX contexts
                    pattern2 = rf"(\()\s*{escaped_name}(?=\s*[\[\,\)])"
                    content_before = content
                    content = re.sub(pattern2, rf"\1{table_quoted}", content)
                    file_fixes += len(re.findall(pattern2, content_before))

                if content != original_content:
                    with open(tmdl_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    files_modified.append(str(tmdl_file))
                    total_fixes += file_fixes
                    logger.info(f"Fixed {file_fixes} DAX quote references in {tmdl_file}")

            except Exception as e:
                logger.error(f"Error fixing DAX in {tmdl_file}: {e}")
                errors.append({"file": str(tmdl_file), "error": str(e)})

        return {
            "files_modified": files_modified,
            "count": total_fixes,
            "tables_fixed": tables_needing_quotes,
            "errors": errors
        }

    # ==================== RENAME OPERATIONS ====================

    def rename_table_in_files(self, old_name: str, new_name: str) -> RenameResult:
        """
        Rename a table across all PBIP files (TMDL + report.json)

        Args:
            old_name: Current table name
            new_name: New table name

        Returns:
            RenameResult with details
        """
        if not self.current_project:
            return RenameResult(False, "No project loaded", [], 0)

        files_modified = []
        total_replacements = 0
        backup_path = None

        # Create backup if enabled
        if self.auto_backup and not self.current_project.backup_path:
            backup_path = self.create_backup()

        # 1. Update TMDL files
        tmdl_replacements = self._rename_table_in_tmdl_files(old_name, new_name)
        files_modified.extend(tmdl_replacements["files"])
        total_replacements += tmdl_replacements["count"]

        # 2. Update report.json
        if self.current_project.report_json_path:
            report_replacements = self._rename_table_in_report_json(old_name, new_name)
            if report_replacements["count"] > 0:
                files_modified.append(str(self.current_project.report_json_path))
                total_replacements += report_replacements["count"]

        # 3. Validate after changes
        validation_errors = self.validate_tmdl_syntax()

        return RenameResult(
            success=len(validation_errors) == 0,
            message=f"Renamed table '{old_name}' to '{new_name}' in {len(files_modified)} file(s)" +
                    (f" with {len(validation_errors)} validation error(s)" if validation_errors else ""),
            files_modified=files_modified,
            references_updated=total_replacements,
            details={"old_name": old_name, "new_name": new_name},
            validation_errors=validation_errors,
            backup_created=backup_path
        )

    def rename_column_in_files(self, table_name: str, old_name: str, new_name: str) -> RenameResult:
        """
        Rename a column across all PBIP files

        Args:
            table_name: Table containing the column
            old_name: Current column name
            new_name: New column name

        Returns:
            RenameResult with details
        """
        if not self.current_project:
            return RenameResult(False, "No project loaded", [], 0)

        files_modified = []
        total_replacements = 0
        backup_path = None

        # Create backup if enabled
        if self.auto_backup and not self.current_project.backup_path:
            backup_path = self.create_backup()

        # 1. Update TMDL files
        tmdl_replacements = self._rename_column_in_tmdl_files(table_name, old_name, new_name)
        files_modified.extend(tmdl_replacements["files"])
        total_replacements += tmdl_replacements["count"]

        # 2. Update report.json
        if self.current_project.report_json_path:
            report_replacements = self._rename_column_in_report_json(table_name, old_name, new_name)
            if report_replacements["count"] > 0:
                files_modified.append(str(self.current_project.report_json_path))
                total_replacements += report_replacements["count"]

        return RenameResult(
            success=True,
            message=f"Renamed column '{table_name}'[{old_name}] to [{new_name}] in {len(files_modified)} file(s)",
            files_modified=files_modified,
            references_updated=total_replacements,
            details={"table_name": table_name, "old_name": old_name, "new_name": new_name},
            backup_created=backup_path
        )

    def rename_measure_in_files(self, old_name: str, new_name: str) -> RenameResult:
        """
        Rename a measure across all PBIP files

        Args:
            old_name: Current measure name
            new_name: New measure name

        Returns:
            RenameResult with details
        """
        if not self.current_project:
            return RenameResult(False, "No project loaded", [], 0)

        files_modified = []
        total_replacements = 0
        backup_path = None

        # Create backup if enabled
        if self.auto_backup and not self.current_project.backup_path:
            backup_path = self.create_backup()

        # 1. Update TMDL files
        tmdl_replacements = self._rename_measure_in_tmdl_files(old_name, new_name)
        files_modified.extend(tmdl_replacements["files"])
        total_replacements += tmdl_replacements["count"]

        # 2. Update report.json
        if self.current_project.report_json_path:
            report_replacements = self._rename_measure_in_report_json(old_name, new_name)
            if report_replacements["count"] > 0:
                files_modified.append(str(self.current_project.report_json_path))
                total_replacements += report_replacements["count"]

        return RenameResult(
            success=True,
            message=f"Renamed measure '{old_name}' to '{new_name}' in {len(files_modified)} file(s)",
            files_modified=files_modified,
            references_updated=total_replacements,
            details={"old_name": old_name, "new_name": new_name},
            backup_created=backup_path
        )

    # ==================== TMDL FILE OPERATIONS ====================

    def _rename_table_in_tmdl_files(self, old_name: str, new_name: str) -> Dict[str, Any]:
        """
        Rename table references in TMDL files with proper quoting

        Handles:
        1. Table declarations: table OldName -> table 'New Name'
        2. DAX references: 'OldName'[Column] -> 'New Name'[Column]
        3. Relationship refs: fromTable: OldName -> fromTable: 'New Name'
        4. Relationship names: 'OldName to Table' -> 'New Name to Table'
        """
        files_modified = []
        total_count = 0

        if not self.current_project or not self.current_project.tmdl_files:
            return {"files": files_modified, "count": total_count}

        # Properly quoted new name for TMDL
        new_name_quoted = quote_tmdl_name(new_name)

        # Build regex patterns for old name (handle both quoted and unquoted)
        old_name_escaped = re.escape(old_name)
        old_name_quoted_escaped = re.escape(f"'{old_name}'")

        # Build patterns list
        patterns = []

        # Pattern 1: Table declaration (both quoted and unquoted old names)
        # table OldName -> table 'New Name'
        patterns.append((
            rf'^(\s*)table\s+{old_name_escaped}\s*$',
            rf'\1table {new_name_quoted}',
            re.MULTILINE
        ))
        # table 'OldName' -> table 'New Name'
        patterns.append((
            rf"^(\s*)table\s+'{old_name_escaped}'\s*$",
            rf'\1table {new_name_quoted}',
            re.MULTILINE
        ))

        # Pattern 2: DAX references - 'TableName'[Column]
        patterns.append((
            rf"'{old_name_escaped}'\s*\[",
            f"{new_name_quoted}[",
            0
        ))

        # Pattern 3: DAX references - unquoted TableName[Column]
        # IMPORTANT: Always use the properly quoted version for the new name
        patterns.append((
            rf"(?<!['\w]){old_name_escaped}(?=\s*\[)",
            new_name_quoted,
            0
        ))

        # Pattern 4: 'TableName' in function calls (RELATED, ALL, VALUES, etc.)
        patterns.append((
            rf"'{old_name_escaped}'(?=\s*[,\)\]])",
            new_name_quoted,
            0
        ))

        # Pattern 4b: Unquoted TableName in function calls (e.g., CALCULATE(SUM(OldTable[Col])))
        # This catches: FUNCTION(OldTable or FUNCTION( OldTable
        patterns.append((
            rf"([A-Z]+\s*\(\s*){old_name_escaped}(?=\s*[\[\,])",
            rf"\1{new_name_quoted}",
            re.IGNORECASE
        ))

        # Pattern 4c: Relationship names containing table name (CRITICAL for relationships)
        # Handle: relationship 'OldName to SomeTable' -> relationship 'NewName to SomeTable'
        # The entire name is in quotes, so we need to replace just the table name part inside quotes
        patterns.append((
            rf"(relationship\s+')({old_name_escaped})(\s+to\s+[^']*)'",
            rf"\1{new_name}\3'",
            re.IGNORECASE
        ))
        # Handle: relationship 'SomeTable to OldName' -> relationship 'SomeTable to NewName'
        patterns.append((
            rf"(relationship\s+')([^']*\s+to\s+)({old_name_escaped})'",
            rf"\1\2{new_name}'",
            re.IGNORECASE
        ))
        # Handle unquoted: relationship OldName to SomeTable -> relationship 'NewName' to SomeTable
        patterns.append((
            rf"(relationship\s+){old_name_escaped}(\s+to\s+)",
            rf"\1{new_name_quoted}\2",
            re.IGNORECASE
        ))
        # Handle unquoted: relationship SomeTable to OldName -> relationship SomeTable to 'NewName'
        patterns.append((
            rf"(relationship\s+)(\S+\s+to\s+){old_name_escaped}(?=\s|$)",
            rf"\1\2{new_name_quoted}",
            re.IGNORECASE | re.MULTILINE
        ))

        # Pattern 5: fromTable reference (CRITICAL for relationships)
        # fromTable: OldName -> fromTable: 'New Name'
        patterns.append((
            rf'(fromTable\s*:\s*){old_name_escaped}(?=\s*(?:$|\n|\r|toTable|fromColumn|toColumn))',
            rf'\1{new_name_quoted}',
            re.MULTILINE | re.IGNORECASE
        ))
        # fromTable: 'OldName' -> fromTable: 'New Name'
        patterns.append((
            rf"(fromTable\s*:\s*)'{old_name_escaped}'",
            rf'\1{new_name_quoted}',
            re.IGNORECASE
        ))

        # Pattern 6: toTable reference (CRITICAL for relationships)
        # toTable: OldName -> toTable: 'New Name'
        patterns.append((
            rf'(toTable\s*:\s*){old_name_escaped}(?=\s*(?:$|\n|\r|fromTable|fromColumn|toColumn))',
            rf'\1{new_name_quoted}',
            re.MULTILINE | re.IGNORECASE
        ))
        # toTable: 'OldName' -> toTable: 'New Name'
        patterns.append((
            rf"(toTable\s*:\s*)'{old_name_escaped}'",
            rf'\1{new_name_quoted}',
            re.IGNORECASE
        ))

        for tmdl_file in self.current_project.tmdl_files:
            try:
                # Cache original content for rollback
                self._cache_file_content(tmdl_file)

                with open(tmdl_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                original_content = content
                file_count = 0

                for pattern, replacement, flags in patterns:
                    content, count = re.subn(pattern, replacement, content, flags=flags)
                    file_count += count

                if content != original_content:
                    with open(tmdl_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    files_modified.append(str(tmdl_file))
                    total_count += file_count
                    logger.info(f"Updated {file_count} references in {tmdl_file}")

            except Exception as e:
                logger.error(f"Error updating TMDL file {tmdl_file}: {e}")

        return {"files": files_modified, "count": total_count}

    def _rename_column_in_tmdl_files(self, table_name: str, old_name: str, new_name: str) -> Dict[str, Any]:
        """Rename column references in TMDL files with proper quoting"""
        files_modified = []
        total_count = 0

        if not self.current_project or not self.current_project.tmdl_files:
            return {"files": files_modified, "count": total_count}

        # Quote names if needed
        table_name_quoted = quote_tmdl_name(table_name)
        new_name_quoted = quote_tmdl_name(new_name)

        # For DAX, columns inside brackets don't need external quotes but may need them if they have spaces
        new_col_in_bracket = new_name if not needs_tmdl_quoting(new_name) else new_name

        # Escape for regex
        table_escaped = re.escape(table_name)
        old_escaped = re.escape(old_name)

        # Patterns for column references
        patterns = [
            # 'TableName'[OldColumn] -> 'TableName'[NewColumn]
            (rf"'{table_escaped}'\s*\[\s*{old_escaped}\s*\]", f"{table_name_quoted}[{new_col_in_bracket}]", 0),
            # TableName[OldColumn] -> TableName[NewColumn]
            (rf"(?<!['\w]){table_escaped}\s*\[\s*{old_escaped}\s*\]", f"{table_name}[{new_col_in_bracket}]", 0),
            # TMDL column definition: column OldName -> column NewName
            (rf'^(\s*)column\s+{old_escaped}\s*$', rf'\1column {new_name_quoted}', re.MULTILINE),
            (rf"^(\s*)column\s+'{old_escaped}'\s*$", rf'\1column {new_name_quoted}', re.MULTILINE),
            # fromColumn/toColumn in relationships
            (rf'(fromColumn\s*:\s*){old_escaped}(?=\s|$)', rf'\1{new_name_quoted}', re.MULTILINE),
            (rf"(fromColumn\s*:\s*)'{old_escaped}'", rf'\1{new_name_quoted}', 0),
            (rf'(toColumn\s*:\s*){old_escaped}(?=\s|$)', rf'\1{new_name_quoted}', re.MULTILINE),
            (rf"(toColumn\s*:\s*)'{old_escaped}'", rf'\1{new_name_quoted}', 0),
        ]

        for tmdl_file in self.current_project.tmdl_files:
            try:
                self._cache_file_content(tmdl_file)

                with open(tmdl_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                original_content = content
                file_count = 0

                for pattern, replacement, flags in patterns:
                    content, count = re.subn(pattern, replacement, content, flags=flags)
                    file_count += count

                if content != original_content:
                    with open(tmdl_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    files_modified.append(str(tmdl_file))
                    total_count += file_count

            except Exception as e:
                logger.error(f"Error updating TMDL file {tmdl_file}: {e}")

        return {"files": files_modified, "count": total_count}

    def _rename_measure_in_tmdl_files(self, old_name: str, new_name: str) -> Dict[str, Any]:
        """Rename measure references in TMDL files with proper quoting"""
        files_modified = []
        total_count = 0

        if not self.current_project or not self.current_project.tmdl_files:
            return {"files": files_modified, "count": total_count}

        new_name_quoted = quote_tmdl_name(new_name)
        old_escaped = re.escape(old_name)

        # Patterns for measure references
        patterns = [
            # [MeasureName] references in DAX
            (rf"\[\s*{old_escaped}\s*\]", f"[{new_name}]", 0),
            # TMDL measure definition: measure OldName = -> measure NewName =
            (rf'^(\s*)measure\s+{old_escaped}\s*=', rf'\1measure {new_name_quoted} =', re.MULTILINE),
            (rf"^(\s*)measure\s+'{old_escaped}'\s*=", rf'\1measure {new_name_quoted} =', re.MULTILINE),
        ]

        for tmdl_file in self.current_project.tmdl_files:
            try:
                self._cache_file_content(tmdl_file)

                with open(tmdl_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                original_content = content
                file_count = 0

                for pattern, replacement, flags in patterns:
                    content, count = re.subn(pattern, replacement, content, flags=flags)
                    file_count += count

                if content != original_content:
                    with open(tmdl_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                    files_modified.append(str(tmdl_file))
                    total_count += file_count

            except Exception as e:
                logger.error(f"Error updating TMDL file {tmdl_file}: {e}")

        return {"files": files_modified, "count": total_count}

    # ==================== REPORT.JSON OPERATIONS ====================

    def _rename_table_in_report_json(self, old_name: str, new_name: str) -> Dict[str, Any]:
        """
        Rename table references in report.json

        report.json contains visual field bindings like:
        - "Entity": "TableName"
        - "Property": "ColumnName"
        - queryRef patterns
        """
        if not self.current_project or not self.current_project.report_json_path:
            return {"count": 0}

        try:
            self._cache_file_content(self.current_project.report_json_path)

            with open(self.current_project.report_json_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content
            count = 0

            # Pattern 1: "Entity": "TableName" (exact match for Entity field)
            pattern1 = rf'"Entity"\s*:\s*"{re.escape(old_name)}"'
            replacement1 = f'"Entity": "{new_name}"'
            content, c = re.subn(pattern1, replacement1, content)
            count += c

            # Pattern 2: "Table": "TableName"
            pattern2 = rf'"Table"\s*:\s*"{re.escape(old_name)}"'
            replacement2 = f'"Table": "{new_name}"'
            content, c = re.subn(pattern2, replacement2, content)
            count += c

            # Pattern 3: queryRef with table name (e.g., "TableName.ColumnName")
            pattern3 = rf'"{re.escape(old_name)}\.([^"]+)"'
            replacement3 = rf'"{new_name}.\1"'
            content, c = re.subn(pattern3, replacement3, content)
            count += c

            # Pattern 4: NativeReferenceName with table
            pattern4 = rf'"NativeReferenceName"\s*:\s*"{re.escape(old_name)}"'
            replacement4 = f'"NativeReferenceName": "{new_name}"'
            content, c = re.subn(pattern4, replacement4, content)
            count += c

            if content != original_content:
                with open(self.current_project.report_json_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Updated {count} table references in report.json")

            return {"count": count}

        except Exception as e:
            logger.error(f"Error updating report.json: {e}")
            return {"count": 0, "error": str(e)}

    def _rename_column_in_report_json(self, table_name: str, old_name: str, new_name: str) -> Dict[str, Any]:
        """Rename column references in report.json"""
        if not self.current_project or not self.current_project.report_json_path:
            return {"count": 0}

        try:
            self._cache_file_content(self.current_project.report_json_path)

            with open(self.current_project.report_json_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content
            count = 0

            # Pattern 1: Table.Column pattern in queryRef
            pattern1 = rf'"{re.escape(table_name)}\.{re.escape(old_name)}"'
            replacement1 = f'"{table_name}.{new_name}"'
            content, c = re.subn(pattern1, replacement1, content)
            count += c

            # Pattern 2: Use JSON parsing for Property fields with Entity context
            try:
                report_data = json.loads(content)
                modified = self._deep_rename_column_in_json(report_data, table_name, old_name, new_name)
                if modified > 0:
                    content = json.dumps(report_data, indent=2, ensure_ascii=False)
                    count += modified
            except json.JSONDecodeError:
                # Fall back to regex if JSON parsing fails
                pass

            if content != original_content:
                with open(self.current_project.report_json_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Updated {count} column references in report.json")

            return {"count": count}

        except Exception as e:
            logger.error(f"Error updating report.json: {e}")
            return {"count": 0, "error": str(e)}

    def _deep_rename_column_in_json(self, obj: Any, table_name: str, old_name: str, new_name: str) -> int:
        """Recursively rename column references in JSON structure"""
        count = 0

        if isinstance(obj, dict):
            # Check if this dict has Entity=table_name and Property=old_name
            if obj.get("Entity") == table_name and obj.get("Property") == old_name:
                obj["Property"] = new_name
                count += 1

            # Also check for NativeReferenceName pattern
            if "NativeReferenceName" in obj:
                ref = obj["NativeReferenceName"]
                if isinstance(ref, str) and ref == f"{table_name}.{old_name}":
                    obj["NativeReferenceName"] = f"{table_name}.{new_name}"
                    count += 1

            # Recurse into nested dicts
            for key, value in obj.items():
                count += self._deep_rename_column_in_json(value, table_name, old_name, new_name)

        elif isinstance(obj, list):
            for item in obj:
                count += self._deep_rename_column_in_json(item, table_name, old_name, new_name)

        return count

    def _rename_measure_in_report_json(self, old_name: str, new_name: str) -> Dict[str, Any]:
        """Rename measure references in report.json"""
        if not self.current_project or not self.current_project.report_json_path:
            return {"count": 0}

        try:
            self._cache_file_content(self.current_project.report_json_path)

            with open(self.current_project.report_json_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content
            count = 0

            # Measures are referenced similarly to columns
            # Pattern: "Property": "MeasureName"
            pattern1 = rf'"Property"\s*:\s*"{re.escape(old_name)}"'
            replacement1 = f'"Property": "{new_name}"'
            content, c = re.subn(pattern1, replacement1, content)
            count += c

            # Pattern: Table.MeasureName in queryRef
            pattern2 = rf'\.{re.escape(old_name)}"'
            replacement2 = f'.{new_name}"'
            content, c = re.subn(pattern2, replacement2, content)
            count += c

            if content != original_content:
                with open(self.current_project.report_json_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Updated {count} measure references in report.json")

            return {"count": count}

        except Exception as e:
            logger.error(f"Error updating report.json: {e}")
            return {"count": 0, "error": str(e)}

    # ==================== BATCH OPERATIONS ====================

    def batch_rename_tables(self, renames: List[Dict[str, str]]) -> RenameResult:
        """
        Batch rename multiple tables in PBIP files

        Args:
            renames: List of {"old_name": "...", "new_name": "..."} dicts

        Returns:
            RenameResult with combined results
        """
        if not self.current_project:
            return RenameResult(False, "No project loaded", [], 0)

        all_files: Set[str] = set()
        total_refs = 0
        results = []
        all_validation_errors: List[ValidationError] = []
        backup_path = None

        # Create backup before any changes
        if self.auto_backup:
            backup_path = self.create_backup()

        for rename in renames:
            old_name = rename.get("old_name")
            new_name = rename.get("new_name")

            if not old_name or not new_name:
                continue

            result = self.rename_table_in_files(old_name, new_name)
            results.append(result)
            all_files.update(result.files_modified)
            total_refs += result.references_updated
            all_validation_errors.extend(result.validation_errors)

        # Final validation
        final_validation = self.validate_tmdl_syntax()
        all_validation_errors.extend(final_validation)

        success = len(all_validation_errors) == 0

        message = f"Renamed {len(renames)} table(s) in PBIP files. Updated {total_refs} references in {len(all_files)} file(s)."
        if not success:
            message += f" WARNING: {len(all_validation_errors)} validation error(s) found!"

        return RenameResult(
            success=success,
            message=message,
            files_modified=list(all_files),
            references_updated=total_refs,
            details={"individual_results": [r.__dict__ for r in results]},
            validation_errors=all_validation_errors,
            backup_created=backup_path
        )

    def batch_rename_columns(self, renames: List[Dict[str, str]]) -> RenameResult:
        """
        Batch rename multiple columns in PBIP files

        Args:
            renames: List of {"table_name": "...", "old_name": "...", "new_name": "..."} dicts

        Returns:
            RenameResult with combined results
        """
        if not self.current_project:
            return RenameResult(False, "No project loaded", [], 0)

        all_files: Set[str] = set()
        total_refs = 0
        results = []
        backup_path = None

        # Create backup before any changes
        if self.auto_backup:
            backup_path = self.create_backup()

        for rename in renames:
            table_name = rename.get("table_name")
            old_name = rename.get("old_name")
            new_name = rename.get("new_name")

            if not all([table_name, old_name, new_name]):
                continue

            result = self.rename_column_in_files(table_name, old_name, new_name)
            results.append(result)
            all_files.update(result.files_modified)
            total_refs += result.references_updated

        return RenameResult(
            success=True,
            message=f"Renamed {len(renames)} column(s) in PBIP files. Updated {total_refs} references in {len(all_files)} file(s).",
            files_modified=list(all_files),
            references_updated=total_refs,
            details={"individual_results": [r.__dict__ for r in results]},
            backup_created=backup_path
        )

    def batch_rename_measures(self, renames: List[Dict[str, str]]) -> RenameResult:
        """
        Batch rename multiple measures in PBIP files

        Args:
            renames: List of {"old_name": "...", "new_name": "..."} dicts

        Returns:
            RenameResult with combined results
        """
        if not self.current_project:
            return RenameResult(False, "No project loaded", [], 0)

        all_files: Set[str] = set()
        total_refs = 0
        results = []
        backup_path = None

        # Create backup before any changes
        if self.auto_backup:
            backup_path = self.create_backup()

        for rename in renames:
            old_name = rename.get("old_name")
            new_name = rename.get("new_name")

            if not old_name or not new_name:
                continue

            result = self.rename_measure_in_files(old_name, new_name)
            results.append(result)
            all_files.update(result.files_modified)
            total_refs += result.references_updated

        return RenameResult(
            success=True,
            message=f"Renamed {len(renames)} measure(s) in PBIP files. Updated {total_refs} references in {len(all_files)} file(s).",
            files_modified=list(all_files),
            references_updated=total_refs,
            details={"individual_results": [r.__dict__ for r in results]},
            backup_created=backup_path
        )
